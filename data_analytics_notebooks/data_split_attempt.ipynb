{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to place the split data\n",
    "path = 'data_splits/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only load these specific columns\n",
    "columns_to_load = [\"DAYOFSERVICE\", \"TRIPID\", \"PROGRNUMBER\", \"STOPPOINTID\", \"PLANNEDTIME_ARR\",\n",
    "                  \"PLANNEDTIME_DEP\", \"ACTUALTIME_ARR\", \"ACTUALTIME_DEP\", \"VEHICLEID\", \"LASTUPDATE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv in chunks of 1,000,000 rows\n",
    "df_chunk = pd.read_csv('rt_leavetimes_DB_2018.txt', sep = \";\",chunksize=1000000,usecols = columns_to_load, dtype =\n",
    "                     {\"PROGRNUMBER\":np.int16, \"STOPPOINTID\":np.int16, \"TRIPID\":np.int32,\n",
    "                      \"PLANNEDTIME_ARR\":np.int32, \"PLANNEDTIME_DEP\":np.int32, \n",
    "                      \"ACTUALTIME_ARR\":np.int32, \"ACTUALTIME_DEP\":np.int32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to create three seperate dictionaries containing required features from rt_trips_DB_2018\n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"Dublinbus\",\n",
    "  passwd=\"Dublinbus\",\n",
    "  database=\"Dublinbus\",\n",
    "    port=3306\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "mycursor.execute(\"SELECT tripid,lineid,routeid,direction FROM rt_trips_DB_2018\")\n",
    "\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "trips_dict_route = {}\n",
    "trips_route_id = {}\n",
    "trips_direction = {}\n",
    "\n",
    "for item in myresult:\n",
    "    trips_dict_route[item[0]] = item[1]\n",
    "    trips_route_id[item[0]] = item[2]\n",
    "    trips_direction[item[0]] = item[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Automated chunking of csv\n",
    "# Addition of required information from the trips data file\n",
    "file_num = 1\n",
    "for chunk in df_chunk:\n",
    "    \n",
    "    chunk['ROUTE']= chunk['TRIPID'].map(trips_dict_route)\n",
    "    chunk['ROUTE_ID']= chunk['TRIPID'].map(trips_route_id)\n",
    "    chunk['DIRECTION']= chunk['TRIPID'].map(trips_direction)\n",
    "    \n",
    "    chunk.to_csv(path + 'chunk_data_' + str(file_num) + '.csv', index=False)\n",
    "    file_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of all bus routes \n",
    "all_routes = []\n",
    "\n",
    "for item in myresult:\n",
    "    all_routes.append(item[1])\n",
    "    \n",
    "all_routes = set(all_routes)\n",
    "all_routes = list(all_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of file names for the bus routes\n",
    "file_name_list = []\n",
    "for name in range(1,5):\n",
    "    file_name_list.append('chunk_data_' + str(name) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens each file in order of name in the list\n",
    "# For each route, filters the dataframe, appends to a file with the route name\n",
    "# This is carried out for all data_chunks and routes\n",
    "\n",
    "for name in file_name_list:\n",
    "    \n",
    "    df = pd.read_csv(path + name, sep=\",\")\n",
    "    \n",
    "    for route in all_routes:\n",
    "        \n",
    "        df_route = df[df['ROUTE'] == route]\n",
    "        \n",
    "        with open(path + 'route_data_files/' + route + '_dataset.csv', 'a') as file:\n",
    "            df_route.to_csv(file, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
